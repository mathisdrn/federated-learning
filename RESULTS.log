==================================================
Project: Federated Learning for Medical Diagnosis
Dataset: Diabetes 130-US Hospitals (1999-2008)
==================================================

[Scenario 1] IID Data - FedAvg
------------------------------
Loading data...
Splitting data (iid)...
Initializing FedAVG with 5 clients...
Starting training for 10 rounds...

Evaluating final model...
Final Global Metrics: {'accuracy': 0.63214, 'macro_precision': 0.63078, 'macro_recall': 0.62456, 'macro_f1': 0.62363, 'micro_precision': 0.63214, 'micro_recall': 0.63214, 'micro_f1': 0.63214, 'runtime_seconds': 62.51}
FedAVG Experiment finished in 62.51s.

[Scenario 2] Non-IID Data (Dirichlet Skew) - FedAvg
---------------------------------------------------
Loading data...
Splitting data (dir)...
Initializing FedAVG with 5 clients...
Starting training for 10 rounds...

Evaluating final model...
Final Global Metrics: {'accuracy': 0.62857, 'macro_precision': 0.63906, 'macro_recall': 0.61363, 'macro_f1': 0.60335, 'micro_precision': 0.62857, 'micro_recall': 0.62857, 'micro_f1': 0.62857, 'runtime_seconds': 59.43}
FedAVG Experiment finished in 59.43s.

[Scenario 3] Non-IID Data (Dirichlet Skew) - FedProx (Treatment)
----------------------------------------------------------------
Loading data...
Splitting data (dir)...
Initializing FedProx with 5 clients...
Starting training for 10 rounds...

Evaluating final model...
Final Global Metrics: {'accuracy': 0.61948, 'macro_precision': 0.6263, 'macro_recall': 0.60514, 'macro_f1': 0.59556, 'micro_precision': 0.61948, 'micro_recall': 0.61948, 'micro_f1': 0.61948, 'runtime_seconds': 73.98}
FedProx Experiment finished in 73.98s.

[Scenario 4] Privacy Preservation - DPFedAVG
------------------------------------------------
Running with Moderate Privacy (Noise Multiplier=1.0)...
Loading data...
Splitting data (iid)...
Initializing DPFedAVG with 5 clients...
Starting training for 10 rounds...
[UserWarning] /Users/mathisderenne/Documents/02 - Scolaire/M2 MIASHS/federated-learning/.venv/lib/python3.12/site-packages/opacus/privacy_engine.py:96
Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before 
production with ``secure_mode`` turned on.
[UserWarning] sys:1
Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See 
https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.

Evaluating final model...
Final Global Metrics: {'accuracy': 0.62033, 'macro_precision': 0.6292, 'macro_recall': 0.60524, 'macro_f1': 0.59422, 'micro_precision': 0.62033, 'micro_recall': 0.62033, 'micro_f1': 0.62033, 'runtime_seconds': 282.41}
DPFedAVG Experiment finished in 282.41s.

Running with High Privacy (Noise Multiplier=2.0)...
Loading data...
Splitting data (iid)...
Initializing DPFedAVG with 5 clients...
Starting training for 10 rounds...
[UserWarning] /Users/mathisderenne/Documents/02 - Scolaire/M2 MIASHS/federated-learning/.venv/lib/python3.12/site-packages/opacus/privacy_engine.py:96
Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before 
production with ``secure_mode`` turned on.
[UserWarning] sys:1
Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See 
https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.

Evaluating final model...
Final Global Metrics: {'accuracy': 0.61139, 'macro_precision': 0.63413, 'macro_recall': 0.59151, 'macro_f1': 0.56727, 'micro_precision': 0.61139, 'micro_recall': 0.61139, 'micro_f1': 0.61139, 'runtime_seconds': 269.27}
DPFedAVG Experiment finished in 269.27s.

[Scenario 5] Fairness & Scalability
-----------------------------------

Running Fairness Analysis with Mitigation (Lambda=0.5)...
Loading data...
Splitting data (iid)...
Initializing FairFedAVG with 5 clients...
Starting training for 10 rounds...

Evaluating final model...
Final Global Metrics: {'accuracy': 0.6323433518409729, 'macro_precision': 0.6316335201263428, 'macro_recall': 0.6239586472511292, 'macro_f1': 0.6224889755249023, 'micro_precision': 0.6323433518409729, 'micro_recall': 0.6323433518409729, 'micro_f1': 0.6323433518409729, 'demographic_parity': 0.052459657192230225, 'equal_opportunity': 0.05903971195220947, 'runtime_seconds': 70.27}
FairFedAVG Experiment finished in 70.27s.

[Scenario 5.2] Scalability Test (50 Clients, 20% Participation)
---------------------------------------------------------------
Loading data...
Splitting data (iid)...
Initializing FedAVG with 50 clients...
Starting training for 5 rounds...

Evaluating final model...
Final Global Metrics: {'accuracy': 0.61013, 'macro_precision': 0.61715, 'macro_recall': 0.59475, 'macro_f1': 0.58257, 'micro_precision': 0.61013, 'micro_recall': 0.61013, 'micro_f1': 0.61013, 'runtime_seconds': 9.54}
FedAVG Experiment finished in 9.54s.